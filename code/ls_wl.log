nohup: 忽略输入

 
                    _ooOoo_
                   o8888888o    __________________________________
                   88" . "88   |  数据处理无错误  模型改进超有效  |
                   (| -_- |)   |  运行不会突中断  高高兴兴发论文  |
                    O\ = /O    <__________________________________|
                ____/`---'\____
              .   ' \\| |// `.
               / \\||| : |||// \
             / _||||| -:- |||||- \
               | | \\\ - /// | |
             | \_| ''\---/'' | |
              \ .-\__ `-` ___/-. /
           ___`. .' /--.--\ `. . __
        ."" '< `.___\_<|>_/___.' >'"".
       | | : `- \`.;`\ _ /`;.`/ - ` : | |
         \ \ `-. \_ __\ /__ _/ .-` / /
 ======`-.____`-.___\_____/___.-`____.-'======
                    `=---='
 
 .............................................
          佛祖保佑             世界和平

/home/ldmc/anaconda3/envs/anlin_env/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:363: UserWarning: Single-Process Multi-GPU is not the recommended mode for DDP. In this mode, each DDP instance operates on multiple devices and creates multiple module replicas within one process. The overhead of scatter/gather and GIL contention in every forward pass can slow down training. Please consider using one DDP instance per device or per module replica by explicitly setting device_ids or CUDA_VISIBLE_DEVICES. 
  warnings.warn(
f1: 0.6172997319207615, p: 0.5064846416382253, r: 0.7902023429179978
Current F1 0.6172997319207615 is better than before 0
f1: 0.6528687944793313, p: 0.5373237014103888, r: 0.8317358892438764
Current F1 0.6528687944793313 is better than before 0.6172997319207615
f1: 0.6050406097729969, p: 0.4679673849737915, r: 0.8556975505857295
f1: 0.6283463923543753, p: 0.4925914726338071, r: 0.8674121405750799
f1: 0.6296953731678768, p: 0.48937426210153484, r: 0.8828541001064962
f1: 0.584465405992962, p: 0.44380005523336097, r: 0.8556975505857295
f1: 0.6309910031667785, p: 0.49210134128166916, r: 0.8791267305644302
f1: 0.6229843211708305, p: 0.4897896982627248, r: 0.8556975505857295
f1: 0.6249226813180391, p: 0.49131362389515393, r: 0.858359957401491
f1: 0.6482214028483928, p: 0.5197685631629702, r: 0.8610223642172524
f1: 0.6486655758617568, p: 0.5193723983349343, r: 0.8636847710330139
f1: 0.6567844036380543, p: 0.5306657920629715, r: 0.8615548455804047
Current F1 0.6567844036380543 is better than before 0.6528687944793313
f1: 0.647865735829805, p: 0.5187319884726225, r: 0.8626198083067093
f1: 0.6643251513434967, p: 0.5420592193808883, r: 0.8578274760383386
Current F1 0.6643251513434967 is better than before 0.6567844036380543
f1: 0.6712395166804119, p: 0.5508879781420765, r: 0.8588924387646433
Current F1 0.6712395166804119 is better than before 0.6643251513434967
f1: 0.6632205255084941, p: 0.5416526138279932, r: 0.8551650692225772
f1: 0.6605118697282927, p: 0.537, r: 0.8578274760383386
f1: 0.6688818148222997, p: 0.5490263067987701, r: 0.8556975505857295
f1: 0.6666619064277902, p: 0.5469123166154896, r: 0.8535676251331203
f1: 0.6670780518450006, p: 0.5474726775956285, r: 0.8535676251331203
threshold: 0.4, f1: 0.6537076841892695, p: 0.5307206908003985, r: 0.8509052183173589.
threshold: 0.45, f1: 0.6610191994284491, p: 0.5397842211732974, r: 0.8525026624068157.
threshold: 0.5, f1: 0.6670780518450006, p: 0.5474726775956285, r: 0.8535676251331203.
threshold: 0.55, f1: 0.6760634155068069, p: 0.5589975635224504, r: 0.8551650692225772.
threshold: 0.6, f1: 0.6795286109079284, p: 0.5646810010574551, r: 0.853035143769968.
threshold: 0.65, f1: 0.6824392461443168, p: 0.5725631768953069, r: 0.8445154419595314.
threshold: 0.7, f1: 0.6913962973969361, p: 0.5857988165680473, r: 0.8434504792332268.
