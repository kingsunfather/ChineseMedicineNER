
 
                    _ooOoo_
                   o8888888o    __________________________________
                   88" . "88   |  数据处理无错误  模型改进超有效  |
                   (| -_- |)   |  运行不会突中断  高高兴兴发论文  |
                    O\ = /O    <__________________________________|
                ____/`---'\____
              .   ' \\| |// `.
               / \\||| : |||// \
             / _||||| -:- |||||- \
               | | \\\ - /// | |
             | \_| ''\---/'' | |
              \ .-\__ `-` ___/-. /
           ___`. .' /--.--\ `. . __
        ."" '< `.___\_<|>_/___.' >'"".
       | | : `- \`.;`\ _ /`;.`/ - ` : | |
         \ \ `-. \_ __\ /__ _/ .-` / /
 ======`-.____`-.___\_____/___.-`____.-'======
                    `=---='
 
 .............................................
          佛祖保佑             世界和平

/home/ldmc/anaconda3/envs/anlin_env/lib/python3.8/site-packages/torch/nn/parallel/distributed.py:363: UserWarning: Single-Process Multi-GPU is not the recommended mode for DDP. In this mode, each DDP instance operates on multiple devices and creates multiple module replicas within one process. The overhead of scatter/gather and GIL contention in every forward pass can slow down training. Please consider using one DDP instance per device or per module replica by explicitly setting device_ids or CUDA_VISIBLE_DEVICES. 
  warnings.warn(
f1: 0.6437527511484022, p: 0.6008306414397785, r: 0.6932907348242812
Current F1 0.6437527511484022 is better than before 0
f1: 0.6735446852987306, p: 0.6255707762557078, r: 0.7294994675186368
Current F1 0.6735446852987306 is better than before 0.6437527511484022
f1: 0.6839921924334672, p: 0.619438444924406, r: 0.7635782747603834
Current F1 0.6839921924334672 is better than before 0.6735446852987306
f1: 0.6793494177515398, p: 0.6203255609326881, r: 0.7507987220447284
f1: 0.6079602946893577, p: 0.7312874251497006, r: 0.520234291799787
f1: 0.708381127781156, p: 0.6756887385210246, r: 0.744408945686901
Current F1 0.708381127781156 is better than before 0.6839921924334672
f1: 0.6623441874664797, p: 0.7406188281764319, r: 0.5990415335463258
f1: 0.708224446529752, p: 0.6660412757973734, r: 0.7561235356762513
f1: 0.69376617766166, p: 0.6794282797345584, r: 0.7087326943556975
f1: 0.6890975641902063, p: 0.6913183279742765, r: 0.6869009584664537
f1: 0.706981446422719, p: 0.6925434116445353, r: 0.7220447284345048
f1: 0.6893705081172765, p: 0.700164744645799, r: 0.6789137380191693
f1: 0.6929167669347808, p: 0.6925531914893617, r: 0.6932907348242812
f1: 0.7015350956630294, p: 0.6996822033898306, r: 0.7034078807241747
f1: 0.7083943664348078, p: 0.7028301886792453, r: 0.7140575079872205
Current F1 0.7083943664348078 is better than before 0.708381127781156
f1: 0.7156987511387145, p: 0.6855192588980985, r: 0.7486687965921193
Current F1 0.7156987511387145 is better than before 0.7083943664348078
f1: 0.7002014031769795, p: 0.6791791791791791, r: 0.722577209797657
f1: 0.7137421883960327, p: 0.6758686339838172, r: 0.7561235356762513
f1: 0.7102514171080806, p: 0.6849653808110782, r: 0.7374866879659212
f1: 0.7095896706006959, p: 0.6846534653465347, r: 0.7364217252396166
threshold: 0.45, f1: 0.7092505485423743, p: 0.6720686367969495, r: 0.7507987220447284.
threshold: 0.5, f1: 0.7095896706006959, p: 0.6846534653465347, r: 0.7364217252396166.
threshold: 0.55, f1: 0.7015931150144582, p: 0.6905621454357916, r: 0.7129925452609158.
threshold: 0.6, f1: 0.6985698862526522, p: 0.7055947854426942, r: 0.6916932907348243.
threshold: 0.65, f1: 0.6925569895312638, p: 0.7174657534246576, r: 0.6693290734824281.
threshold: 0.7, f1: 0.6868066536004104, p: 0.7312086590499098, r: 0.6474973375931843.
